{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d4a089-c88c-4836-97f1-049ab4e9705d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark.conf.set(\n",
    "  \"<storage account name>\"\n",
    "  \"<access key>\"\n",
    ")\n",
    "\n",
    "container = [\"raw\", \"curated\", \"presentation\"]\n",
    "storage   = \"adlsdemodevde\"\n",
    "\n",
    "raw_base = f\"abfss://{container[0]}@{storage}.dfs.core.windows.net/raw/retail\"\n",
    "curated_base = f\"abfss://{container[1]}@{storage}.dfs.core.windows.net\"\n",
    "presentation_base = f\"abfss://{container[2]}@{storage}.dfs.core.windows.net/presentation/retail\"\n",
    "bronze_base = f\"{curated_base}/bronze\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6344beb0-dace-433c-be2b-7e468afd3485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_df = (\n",
    "    spark.range(1, 1_000_001)\n",
    "    .withColumnRenamed(\"id\", \"order_id\")\n",
    "    .withColumn(\"order_ts\", current_timestamp())\n",
    "    .withColumn(\"customer_id\", (rand() * 50_000).cast(\"int\") + 1)\n",
    "    .withColumn(\"product_id\", (rand() * 500).cast(\"int\") + 1)\n",
    "    .withColumn(\n",
    "        \"country\",\n",
    "        when(rand() < 0.7, \"India\")\n",
    "        .when(rand() < 0.9, \"USA\")\n",
    "        .otherwise(\"UK\")\n",
    "    )\n",
    "    .withColumn(\"quantity\", (rand() * 5 + 1).cast(\"int\"))\n",
    "    .withColumn(\"unit_price\", (rand() * 2000 + 100))\n",
    ")\n",
    "\n",
    "orders_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(f\"{raw_base}/orders\")\n",
    "# dbutils.fs.ls(f\"{raw_base}/orders\")\n",
    "customers_df = (\n",
    "    spark.range(1, 50_001)\n",
    "    .withColumnRenamed(\"id\", \"customer_id\")\n",
    "    .withColumn(\"customer_name\", concat(lit(\"Customer-\"), col(\"customer_id\")))\n",
    "    .withColumn(\"email\", concat(col(\"customer_name\"), lit(\"@mail.com\")))\n",
    "    .withColumn(\n",
    "        \"country\",\n",
    "        when(rand() < 0.65, \"India\")\n",
    "        .when(rand() < 0.85, \"USA\")\n",
    "        .otherwise(\"UK\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"signup_date\",\n",
    "        date_sub(current_date(), (rand() * 1000).cast(\"int\"))\n",
    "    )\n",
    "    .withColumn(\"is_active\", rand() > 0.1)\n",
    ")\n",
    "\n",
    "customers_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(f\"{raw_base}/customers\")\n",
    "products_df = (\n",
    "    spark.range(1, 501)\n",
    "    .withColumnRenamed(\"id\", \"product_id\")\n",
    "    .withColumn(\"product_name\", concat(lit(\"Product-\"), col(\"product_id\")))\n",
    "    .withColumn(\n",
    "        \"category\",\n",
    "        when(col(\"product_id\") % 4 == 0, \"Electronics\")\n",
    "        .when(col(\"product_id\") % 4 == 1, \"Clothing\")\n",
    "        .when(col(\"product_id\") % 4 == 2, \"Grocery\")\n",
    "        .otherwise(\"Home\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"sub_category\",\n",
    "        when(col(\"category\") == \"Electronics\", \"Mobile\")\n",
    "        .when(col(\"category\") == \"Clothing\", \"Men\")\n",
    "        .otherwise(\"General\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"brand\",\n",
    "        when(rand() < 0.5, \"BrandA\").otherwise(\"BrandB\")\n",
    "    )\n",
    ")\n",
    "\n",
    "products_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(f\"{raw_base}/products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d839baa-6379-4658-ada6-ace13bbd6abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_orders = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(f\"{raw_base}/orders\")\n",
    "raw_customers = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(f\"{raw_base}/customers\")\n",
    "raw_products = spark.read \\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(f\"{raw_base}/products\")\n",
    "# ======================================\n",
    "\n",
    "raw_orders.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(f\"{bronze_base}/orders\")\n",
    "\n",
    "raw_customers.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(f\"{bronze_base}/customers\")\n",
    "\n",
    "raw_products.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(f\"{bronze_base}/products\")\n",
    "\n",
    "# ======================================\n",
    "\n",
    "bronze_orders = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_base}/orders\"\n",
    ")\n",
    "bronze_customers = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_base}/customers\"\n",
    ")\n",
    "bronze_products = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_base}/products\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "753d30c4-bd0e-4c96-ae34-e4078e5952d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_clean = bronze_orders.filter(\n",
    "    \"order_id IS NOT NULL AND customer_id IS NOT NULL AND product_id IS NOT NULL\"\n",
    ")\n",
    "\n",
    "customers_clean = bronze_customers.filter(\"customer_id IS NOT NULL\")\n",
    "products_clean  = bronze_products.filter(\"product_id IS NOT NULL\")\n",
    "\n",
    "orders_clean = orders_clean.withColumnRenamed(\n",
    "    \"country\", \"order_country\"\n",
    ")\n",
    "\n",
    "customers_clean = customers_clean.withColumnRenamed(\n",
    "    \"country\", \"customer_country\"\n",
    ")\n",
    "products_clean = products_clean.withColumnRenamed(\n",
    "    \"country\", \"product_country\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d73b221-28a8-4b8d-8e4e-02df64176fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "orders_with_products = (\n",
    "    orders_clean\n",
    "    .join(\n",
    "        broadcast(products_clean),\n",
    "        on=\"product_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "silver_enriched = (\n",
    "    orders_with_products\n",
    "    .join(\n",
    "        customers_clean,\n",
    "        on=\"customer_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "silver_base = f\"abfss://{container[1]}@{storage}.dfs.core.windows.net/silver\"\n",
    "\n",
    "silver_enriched.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .partitionBy(\"order_country\") \\\n",
    "    .save(f\"{silver_base}/orders_enriched\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48f0408-6402-4e8f-ab60-35edbf6511fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\") \\\n",
    "    .load(f\"{silver_base}/orders_enriched\") \\\n",
    "    .groupBy(\"order_country\") \\\n",
    "    .count() \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615e5858-0bb5-4c13-afdb-9503f5d530e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = spark.read.format(\"delta\").load(\n",
    "    f\"{silver_base}/orders_enriched\"\n",
    ")\n",
    "\n",
    "gold_country_sales = (\n",
    "    silver_df\n",
    "    .groupBy(\"order_country\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_orders\"),\n",
    "        sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        sum(col(\"quantity\").cast(\"float\") * col(\"unit_price\").cast(\"float\")).alias(\"total_revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gold_country_sales.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(f\"{presentation_base}/country_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd389d6-142f-48dc-9df8-c8f453ca7a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\") \\\n",
    "    .load(f\"{presentation_base}/country_sales\") \\\n",
    "    .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "retail_ETL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
